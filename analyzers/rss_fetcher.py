import hashlib
import email.utils
from datetime import datetime
from typing import Dict, Optional

import feedparser

from analyzers.ai_analyzer import AIAnalyzer
from notifiers.dingtalk import DingTalkNotifier
from storage.state_manager import StateManager


class RSSFetcher:
    """RSSæ–‡ç« ç›‘æ§å™¨"""

    def __init__(
        self,
        feed_url: str,
        state_manager: StateManager,
        ai_analyzer: AIAnalyzer,
        notifier: DingTalkNotifier,
    ):
        self.feed_url = feed_url
        self.state_manager = state_manager
        self.ai_analyzer = ai_analyzer
        self.notifier = notifier

        # åˆå§‹åŒ–å†å²è®°å½•
        self.state_manager.ensure_key("rss_history", {})

    def check_and_analyze(self):
        """æ£€æŸ¥æ–°æ–‡ç« å¹¶åˆ†æ"""
        print(f"\n[{datetime.now().strftime('%Y-%m-%d %H:%M:%S')}] RSS Check")

        try:
            # è§£æRSS Feedï¼ˆæ·»åŠ è¶…æ—¶ï¼‰
            import socket
            old_timeout = socket.getdefaulttimeout()
            socket.setdefaulttimeout(30)  # 30ç§’è¶…æ—¶

            try:
                feed = feedparser.parse(self.feed_url)
            finally:
                socket.setdefaulttimeout(old_timeout)

            if not feed.entries:
                print("No entries in RSS feed")
                return

            # ä»…å¤„ç†å½“å¤©æ–‡ç« 
            today = datetime.now().date()
            today_entries = [
                entry for entry in feed.entries if self._is_entry_today(entry, today)
            ]
            if not today_entries:
                print("No articles for today")
                return

            # éå†æ–‡ç« 
            history = self.state_manager.get("rss_history", {})
            new_articles_found = False
            processed_count = 0
            max_articles_per_run = 1  # å•æ¬¡åªå¤„ç†1ç¯‡æ–‡ç« ï¼Œå¤šç¯‡æ–‡ç« ä¼šåœ¨åç»­è¿è¡Œä¸­é€ä¸ªå¤„ç†

            for entry in today_entries:
                # é™åˆ¶å¤„ç†æ•°é‡ï¼Œé¿å…ä»»åŠ¡æ—¶é—´è¿‡é•¿
                if processed_count >= max_articles_per_run:
                    print(f"Reached max articles limit ({max_articles_per_run}), will process remaining in next run")
                    break

                article_id = self._generate_article_id(entry)

                # æ£€æŸ¥æ˜¯å¦å·²å¤„ç†
                if article_id in history:
                    continue

                # å‘ç°æ–°æ–‡ç« 
                new_articles_found = True
                print(f"Found new article: {entry.get('title', 'N/A')}")

                # æå–å†…å®¹
                content = self._extract_content(entry)
                if not content:
                    print("Failed to extract content")
                    # æ ‡è®°ä¸ºå·²å¤„ç†ï¼ˆé¿å…é‡å¤å°è¯•ï¼‰
                    history[article_id] = {
                        "processed_at": datetime.now().isoformat(),
                        "title": entry.get("title", ""),
                        "link": entry.get("link", ""),
                        "status": "no_content"
                    }
                    self.state_manager.set("rss_history", history)
                    continue

                # AIåˆ†æ
                try:
                    analysis = self.ai_analyzer.analyze(content)

                    # å‘é€é€šçŸ¥
                    self._send_notification(entry, analysis)

                    # æ ‡è®°ä¸ºå·²å¤„ç†
                    history[article_id] = {
                        "processed_at": datetime.now().isoformat(),
                        "title": entry.get("title", ""),
                        "link": entry.get("link", ""),
                        "status": "analyzed"
                    }
                    self.state_manager.set("rss_history", history)
                    processed_count += 1

                except Exception as e:
                    print(f"Analysis failed: {e}")
                    # æ ‡è®°ä¸ºå¤±è´¥ï¼Œé¿å…æ— é™é‡è¯•
                    history[article_id] = {
                        "processed_at": datetime.now().isoformat(),
                        "title": entry.get("title", ""),
                        "link": entry.get("link", ""),
                        "status": "failed",
                        "error": str(e)
                    }
                    self.state_manager.set("rss_history", history)

            if not new_articles_found:
                print("No new articles found")
            else:
                print(f"Processed {processed_count} articles in this run")

        except Exception as e:
            print(f"[ERROR] RSS check failed: {e}")
            # ä¸è¦raiseï¼Œè®©ä»»åŠ¡æ­£å¸¸ç»“æŸ
            import traceback
            traceback.print_exc()

    def _generate_article_id(self, entry) -> str:
        """ç”Ÿæˆæ–‡ç« å”¯ä¸€ID"""
        if entry.get("id"):
            return entry["id"]

        # ä½¿ç”¨linkå’Œtitleç”Ÿæˆhash
        content = f"{entry.get('link', '')}{entry.get('title', '')}"
        return hashlib.md5(content.encode()).hexdigest()

    def _is_entry_today(self, entry, today) -> bool:
        """åˆ¤æ–­æ–‡ç« æ—¥æœŸæ˜¯å¦ä¸ºå½“å¤©"""
        entry_date = self._get_entry_date(entry)
        return entry_date == today if entry_date else False

    def _get_entry_date(self, entry) -> Optional[datetime.date]:
        """è§£ææ–‡ç« å‘å¸ƒæ—¥æœŸ"""
        time_struct = entry.get("published_parsed") or entry.get("updated_parsed")
        if time_struct:
            try:
                timestamp = feedparser.mktime_tz(time_struct)
                return datetime.fromtimestamp(timestamp).date()
            except Exception:
                try:
                    return datetime(*time_struct[:6]).date()
                except Exception:
                    return None

        date_str = entry.get("published") or entry.get("updated")
        if date_str:
            try:
                dt = email.utils.parsedate_to_datetime(date_str)
                if dt.tzinfo:
                    dt = dt.astimezone()
                return dt.date()
            except Exception:
                return None

        return None

    def _extract_content(self, entry) -> Optional[str]:
        """æå–æ–‡ç« å†…å®¹"""
        # ä¼˜å…ˆä½¿ç”¨content
        if "content" in entry and entry.content:
            return entry.content[0].value

        # å…¶æ¬¡ä½¿ç”¨summary
        if "summary" in entry:
            return entry.summary

        # æœ€åä½¿ç”¨description
        if "description" in entry:
            return entry.description

        return None

    def _send_notification(self, entry, analysis: Dict):
        """å‘é€åˆ†æç»“æœé€šçŸ¥"""
        lines = [
            "ğŸ“° RSSæ–‡ç« æŠ•èµ„åˆ†æ",
            "",
            f"**æ ‡é¢˜**: {entry.get('title', 'N/A')}",
            f"**é“¾æ¥**: {entry.get('link', 'N/A')}",
            f"**å‘å¸ƒæ—¶é—´**: {entry.get('published', 'N/A')}",
            "",
            "---",
            "",
        ]

        # æ ¸å¿ƒè§‚ç‚¹
        if analysis.get("core_summary"):
            lines.append(f"**æ ¸å¿ƒè§‚ç‚¹**: {analysis['core_summary']}")
            lines.append("")

        # å¸‚åœºè§‚ç‚¹
        market_view = analysis.get("market_view", "æœªçŸ¥")
        view_emoji = {"çœ‹å¤š": "ğŸ“ˆ", "çœ‹ç©º": "ğŸ“‰", "ä¸­æ€§": "â¡ï¸"}.get(market_view, "â“")
        lines.append(f"**å¸‚åœºè§‚ç‚¹**: {view_emoji} {market_view}")
        lines.append("")

        # ç›¸å…³è‚¡ç¥¨
        related_items = analysis.get("related_items", {})
        stocks = related_items.get("stocks", [])
        if stocks:
            lines.append("**ç›¸å…³è‚¡ç¥¨**:")
            for stock in stocks[:5]:  # æœ€å¤šæ˜¾ç¤º5åª
                code = stock.get("code", "")
                name = stock.get("name", "")
                market = stock.get("market", "")
                lines.append(f"- {code} {name} ({market})")
            lines.append("")

        # ç›¸å…³è¡Œä¸š
        industries = related_items.get("industries", [])
        if industries:
            lines.append("**ç›¸å…³è¡Œä¸š**:")
            for industry in industries[:3]:  # æœ€å¤šæ˜¾ç¤º3ä¸ª
                name = industry.get("name", "")
                lines.append(f"- {name}")
            lines.append("")

        # æŠ•èµ„ä¸»é¢˜
        themes = related_items.get("investment_themes", [])
        if themes:
            lines.append("**æŠ•èµ„ä¸»é¢˜**:")
            for theme in themes[:3]:  # æœ€å¤šæ˜¾ç¤º3ä¸ª
                name = theme.get("name", "")
                lines.append(f"- {name}")
            lines.append("")

        # ç›¸å…³åŸºé‡‘
        funds = related_items.get("funds", [])
        if funds:
            lines.append("**ç›¸å…³åŸºé‡‘**:")
            for fund in funds[:3]:  # æœ€å¤šæ˜¾ç¤º3ä¸ª
                code = fund.get("code", "")
                name = fund.get("name", "")
                lines.append(f"- {code} {name}")
            lines.append("")

        # å»¶ä¼¸åˆ†ææ‘˜è¦
        extended = analysis.get("extended_analysis", {})
        if extended.get("summary"):
            lines.append("**å¸‚åœºåˆ†æ**:")
            summary_text = extended["summary"]
            # å¦‚æœå¤ªé•¿ï¼Œæˆªå–å‰300å­—
            if len(summary_text) > 300:
                summary_text = summary_text[:300] + "..."
            lines.append(summary_text)
            lines.append("")

        # æŠ•èµ„å¯ç¤º
        insights = analysis.get("investment_insights", [])
        if insights:
            lines.append("**æŠ•èµ„å¯ç¤º**:")
            for i, insight in enumerate(insights[:3], 1):  # æœ€å¤šæ˜¾ç¤º3æ¡
                lines.append(f"{i}. {insight}")
            lines.append("")

        lines.append("---")
        lines.append("ğŸ’¡ *AIåˆ†æä»…ä¾›å‚è€ƒï¼Œä¸æ„æˆæŠ•èµ„å»ºè®®*")

        message = "\n".join(lines)
        self.notifier.send_text(message)
